{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **ASSIGNMENT 1**\n",
        "---\n",
        "\n",
        "# **Name:** Vedant Landge\n",
        "# **PRN No:** 20190802005\n",
        "# **Subject:** Advanced AI\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "h436KgCh3EpD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Topic:** FEATURE ENGINEERING ON TEXT DATA."
      ],
      "metadata": {
        "id": "1YOcdg1cgdEG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ju26rSl_Ldz"
      },
      "source": [
        "## **Aim:** To perform segmentation and Feature Engineering on Text data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZgXMulZ_UGA"
      },
      "source": [
        "## **Segment to Extract:** Title and Journal Name."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-zjhTyO_g8U"
      },
      "source": [
        "## **Steps to perform:**\n",
        "\n",
        "1. Data Collection.\n",
        "2. Segments Extraction GroupWise. You can consider synonyms if you don't find the relative keywords.\n",
        "3. Data Preprocessing.\n",
        "4. Feature Engineering.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "8aWzt6Tb3rDq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Installing the Required Libraries**"
      ],
      "metadata": {
        "id": "7ojgXOuo3t8K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Hb--GXr-_TVG",
        "outputId": "b05be8cb-c517-459f-c633-f3b828f0ab29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyPDF2\n",
            "  Downloading PyPDF2-2.11.0-py3-none-any.whl (220 kB)\n",
            "\u001b[K     |████████████████████████████████| 220 kB 31.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.7/dist-packages (from PyPDF2) (4.1.1)\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-2.11.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.1.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.4)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.9.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.7)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "# For Converting the PDF File and Extracting the Contents of the PDF File.\n",
        "!pip install PyPDF2\n",
        "\n",
        "# For Working with Text Data (NLP) like Removing the Punctuations, Stop Words, etc from the data.\n",
        "!pip install nltk\n",
        "!pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2 as pdf\n",
        "\n",
        "# Reading All the 3 PDF Files given by Sulaxan Sir.\n",
        "pdfFile1 = pdf.PdfFileReader(\"1.pdf\")\n",
        "pdfFile2 = pdf.PdfFileReader(\"2.pdf\")\n",
        "pdfFile3 = pdf.PdfFileReader(\"3.pdf\")\n",
        "\n",
        "\n",
        "# Storing the PDF Text Data into respective TXT Files.\n",
        "text1 = \"\"\n",
        "text2 = \"\"\n",
        "text3 = \"\"\n",
        "\n",
        "# As we want to Extract \"TITLE and JOURNAL NAME\", so obviously they are on 1st page so we are extracting 1st page data.\n",
        "text1 = pdfFile1.getPage(0).extractText()\n",
        "text2 = pdfFile2.getPage(0).extractText()\n",
        "text3 = pdfFile3.getPage(0).extractText()\n",
        "\n",
        "\n",
        "# Writing Data to TEXT Files.\n",
        "with open(\"extracted_data_of_pdf_1.txt\", \"w\", encoding = \"utf-8\") as file:\n",
        "  file.write(text1)\n",
        "\n",
        "with open(\"extracted_data_of_pdf_2.txt\", \"w\", encoding = \"utf-8\") as file:\n",
        "  file.write(text2)\n",
        "\n",
        "with open(\"extracted_data_of_pdf_3.txt\", \"w\", encoding = \"utf-8\") as file:\n",
        "  file.write(text3)\n",
        "\n",
        "\n",
        "print(\"Data Extracted and Stored in Respective TXT Files...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3ZAWq51-8ZwX",
        "outputId": "d23ab09f-64e7-4fec-b2d2-62ff4dea971c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Extracted and Stored in Respective TXT Files...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the TXT Files.\n",
        "file1 = open(\"extracted_data_of_pdf_1.txt\", \"r\")\n",
        "file2 = open(\"extracted_data_of_pdf_2.txt\", \"r\")\n",
        "file3 = open(\"extracted_data_of_pdf_3.txt\", \"r\")\n",
        "\n",
        "data1 = file1.read()\n",
        "data2 = file2.read()\n",
        "data3 = file3.read()"
      ],
      "metadata": {
        "id": "OD2Oxkui9yo0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Contents of 1st Text File.\n",
        "print(data1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sDv7bgDRJe_c",
        "outputId": "2f0a40e4-0645-435d-c39b-296dab6e60c9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0162-8828 (c) 2016 IEEE. Translations and content mining are permitted for academic research only. Personal use is also permitted, but republication/redistribution requires IEEE permission. See\n",
            "http://www.ieee.org/publications_standards/publications/rights/index.html for more information.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2016.2644615, IEEE\n",
            "Transactions on Pattern Analysis and Machine Intelligence\n",
            "1\n",
            "SegNet: A Deep Convolutional\n",
            "Encoder-Decoder Architecture for Scene\n",
            "Segmentation\n",
            "Vijay Badrinarayanan, Alex Kendall, Roberto Cipolla, Senior Member, IEEE,\n",
            "Abstract—We present a novel and practical deep fully convolutional neural network architecture for semantic pixel-wise segmentation\n",
            "termed SegNet. This core trainable segmentation engine consists of an encoder network, a corresponding decoder network followed\n",
            "by a pixel-wise classiﬁcation layer. The architecture of the encoder network is topologically identical to the 13 convolutional layers in the\n",
            "VGG16 network [1]. The role of the decoder network is to map the low resolution encoder feature maps to full input resolution feature\n",
            "maps for pixel-wise classiﬁcation. The novelty of SegNet lies is in the manner in which the decoder upsamples its lower resolution input\n",
            "feature map(s). Speciﬁcally, the decoder uses pooling indices computed in the max-pooling step of the corresponding encoder to\n",
            "perform non-linear upsampling. This eliminates the need for learning to upsample. The upsampled maps are sparse and are then\n",
            "convolved with trainable ﬁlters to produce dense feature maps. We compare our proposed architecture with the widely adopted FCN [2]\n",
            "and also with the well known DeepLab-LargeFOV [3], DeconvNet [4] architectures. This comparison reveals the memory versus\n",
            "accuracy trade-off involved in achieving good segmentation performance.\n",
            "SegNet was primarily motivated by scene understanding applications. Hence, it is designed to be efﬁcient both in terms of memory and\n",
            "computational time during inference. It is also signiﬁcantly smaller in the number of trainable parameters than other competing\n",
            "architectures and can be trained end-to-end using stochastic gradient descent. We also performed a controlled benchmark of SegNet\n",
            "and other architectures on both road scenes and SUN RGB-D indoor scene segmentation tasks. These quantitative assessments\n",
            "show that SegNet provides good performance with competitive inference time and most efﬁcient inference memory-wise as compared\n",
            "to other architectures. We also provide a Caffe implementation of SegNet and a web demo at http://mi.eng.cam.ac.uk/projects/segnet/.\n",
            "Index Terms—Deep Convolutional Neural Networks, Semantic Pixel-Wise Segmentation, Indoor Scenes, Road Scenes, Encoder,\n",
            "Decoder, Pooling, Upsampling.\n",
            "F\n",
            "1 I NTRODUCTION\n",
            "Semantic segmentation has a wide array of applications ranging\n",
            "from scene understanding, inferring support-relationships among\n",
            "objects to autonomous driving. Early methods that relied on low-\n",
            "level vision cues have fast been superseded by popular machine\n",
            "learning algorithms. In particular, deep learning has seen huge suc-\n",
            "cess lately in handwritten digit recognition, speech, categorising\n",
            "whole images and detecting objects in images [5], [6]. Now there\n",
            "is an active interest for semantic pixel-wise labelling [7] [8], [9],\n",
            "[2], [4], [10], [11], [12], [13], [3], [14], [15], [16]. However, some\n",
            "of these recent approaches have tried to directly adopt deep archi-\n",
            "tectures designed for category prediction to pixel-wise labelling\n",
            "[7]. The results, although very encouraging, appear coarse [3].\n",
            "This is primarily because max pooling and sub-sampling reduce\n",
            "feature map resolution. Our motivation to design SegNet arises\n",
            "from this need to map low resolution features to input resolution\n",
            "for pixel-wise classiﬁcation. This mapping must produce features\n",
            "which are useful for accurate boundary localization.\n",
            "Our architecture, SegNet, is designed to be an efﬁcient ar-\n",
            "chitecture for pixel-wise semantic segmentation. It is primarily\n",
            "motivated by road scene understanding applications which require\n",
            "the ability to model appearance (road, building), shape (cars,\n",
            "\u000fV . Badrinarayanan, A. Kendall, R. Cipolla are with the Machine Intelli-\n",
            "gence Lab, Department of Engineering, University of Cambridge, UK.\n",
            "E-mail: vb292,agk34,cipolla@eng.cam.ac.ukpedestrians) and understand the spatial-relationship (context) be-\n",
            "tween different classes such as road and side-walk. In typical road\n",
            "scenes, the majority of the pixels belong to large classes such\n",
            "as road, building and hence the network must produce smooth\n",
            "segmentations. The engine must also have the ability to delineate\n",
            "objects based on their shape despite their small size. Hence it is\n",
            "important to retain boundary information in the extracted image\n",
            "representation. From a computational perspective, it is necessary\n",
            "for the network to be efﬁcient in terms of both memory and\n",
            "computation time during inference. The ability to train end-to-end\n",
            "in order to jointly optimise all the weights in the network using\n",
            "an efﬁcient weight update technique such as stochastic gradient\n",
            "descent (SGD) [17] is an additional beneﬁt since it is more easily\n",
            "repeatable. The design of SegNet arose from a need to match these\n",
            "criteria.\n",
            "The encoder network in SegNet is topologically identical to\n",
            "the convolutional layers in VGG16 [1]. We remove the fully\n",
            "connected layers of VGG16 which makes the SegNet encoder\n",
            "network signiﬁcantly smaller and easier to train than many other\n",
            "recent architectures [2], [4], [11], [18]. The key component of\n",
            "SegNet is the decoder network which consists of a hierarchy\n",
            "of decoders one corresponding to each encoder. Of these, the\n",
            "appropriate decoders use the max-pooling indices received from\n",
            "the corresponding encoder to perform non-linear upsampling of\n",
            "their input feature maps. This idea was inspired from an archi-\n",
            "tecture designed for unsupervised feature learning [19]. Reusing\n",
            "max-pooling indices in the decoding process has several practical\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Contents of 2nd Text File.\n",
        "print(data2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zejNKUMdJohe",
        "outputId": "643c1f61-9f31-40ee-fb3c-fac6438b8fb4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0162-8828 (c) 2021 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/TPAMI.2021.3059968, IEEE\n",
            "Transactions on Pattern Analysis and Machine Intelligence\n",
            "TRANSACTIONS ON PATTERN ANAL YSIS AND MACHINE INTELLIGENCE, VOL. ??, NO.??, ?? 2021 1\n",
            "Image Segmentation Using Deep Learning:\n",
            "A Survey\n",
            "Shervin Minaee, Member, IEEE, Yuri Boykov, Member, IEEE, Fatih Porikli, Fellow, IEEE,\n",
            "Antonio Plaza, Fellow, IEEE, Nasser Kehtarnavaz, Fellow, IEEE, and Demetri Terzopoulos, Fellow, IEEE\n",
            "Abstract—Image segmentation is a key task in computer vision and image processing with important applications such as scene\n",
            "understanding, medical image analysis, robotic perception, video surveillance, augmented reality, and image compression, among others,\n",
            "and numerous segmentation algorithms are found in the literature. Against this backdrop, the broad success of Deep Learning (DL) has\n",
            "prompted the development of new image segmentation approaches leveraging DL models. We provide a comprehensive review of this\n",
            "recent literature, covering the spectrum of pioneering efforts in semantic and instance segmentation, including convolutional pixel-labeling\n",
            "networks, encoder-decoder architectures, multiscale and pyramid-based approaches, recurrent networks, visual attention models, and\n",
            "generative models in adversarial settings. We investigate the relationships, strengths, and challenges of these DL-based segmentation\n",
            "models, examine the widely used datasets, compare performances, and discuss promising research directions.\n",
            "Index Terms—Image segmentation, deep learning, convolutional neural networks, encoder-decoder models, recurrent models,\n",
            "generative models, semantic segmentation, instance segmentation, panoptic segmentation, medical image segmentation.\n",
            "F\n",
            "1 I NTRODUCTION\n",
            "IMAGE segmentation has been a fundamental problem in\n",
            "computer vision since the early days of the ﬁeld [1] (Chap-\n",
            "ter 8). An essential component of many visual understanding\n",
            "systems, it involves partitioning images (or video frames)\n",
            "into multiple segments and objects [2] (Chapter 5) and plays\n",
            "a central role in a broad range of applications [3] (Part VI),\n",
            "including medical image analysis (e.g., tumor boundary\n",
            "extraction and measurement of tissue volumes), autonomous\n",
            "vehicles (e.g., navigable surface and pedestrian detection),\n",
            "video surveillance, and augmented reality to name a few.\n",
            "Image segmentation can be formulated as the problem\n",
            "of classifying pixels with semantic labels (semantic seg-\n",
            "mentation), or partitioning of individual objects (instance\n",
            "segmentation), or both (panoptic segmentation). Semantic\n",
            "segmentation performs pixel-level labeling with a set of\n",
            "object categories (e.g., human, car, tree, sky) for all image\n",
            "pixels; thus, it is generally a more demanding undertaking\n",
            "than whole-image classiﬁcation, which predicts a single label\n",
            "for the entire image. Instance segmentation extends the scope\n",
            "of semantic segmentation by detecting and delineating each\n",
            "object of interest in the image (e.g., individual people).\n",
            "Numerous image segmentation algorithms have been\n",
            "developed in the literature, from the earliest methods,\n",
            "such as thresholding [4], histogram-based bundling, region-\n",
            "growing [5], k-means clustering [6], watershed methods [7],\n",
            "to more advanced algorithms such as active contours [8],\n",
            "graph cuts [9], conditional and Markov random ﬁelds [10],\n",
            "and sparsity-based [11], [12] methods. In recent years,\n",
            "however, deep learning (DL) models have yielded a new\n",
            "\u000fS. Minaee is with Snapchat Machine Learning Research.\n",
            "\u000fY. Boykov is with the University of Waterloo.\n",
            "\u000fF. Porikli is with the Australian National University, and Huawei.\n",
            "\u000fA. Plaza is with the University of Extremadura, Spain.\n",
            "\u000fN. Kehtarnavaz is with the University of Texas at Dallas.\n",
            "\u000fD. Terzopoulos is with the University of California, Los Angeles.\n",
            "Manuscript received December ??, 2019; revised ?? ??, 2021.\n",
            "Fig. 1. Segmentation results of DeepLabV3 [13] on sample images.\n",
            "generation of image segmentation models with remarkable\n",
            "performance improvements, often achieving the highest\n",
            "accuracy rates on popular benchmarks (e.g., Fig. 1). This\n",
            "has caused a paradigm shift in the ﬁeld.\n",
            "This survey, a revised version of [14], covers the recent\n",
            "literature in deep-learning-based image segmentation, includ-\n",
            "ing more than 100 such segmentation methods proposed to\n",
            "date. It provides a comprehensive review with insights into\n",
            "different aspects of these methods, including the training\n",
            "data, the choice of network architectures, loss functions,\n",
            "training strategies, and their key contributions. The target\n",
            "literature is organized into the following categories:\n",
            "1) Fully convolutional networks\n",
            "2) Convolutional models with graphical models\n",
            "3) Encoder-decoder based models\n",
            "4) Multiscale and pyramid network based models\n",
            "5) R-CNN based models (for instance segmentation)\n",
            "6) Dilated convolutional models and DeepLab family\n",
            "7) Recurrent neural network based models\n",
            "Authorized licensed use limited to: Carleton University. Downloaded on May 28,2021 at 14:10:11 UTC from IEEE Xplore.  Restrictions apply. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Contents of 3rd Text File.\n",
        "print(data3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pIuUXSKvJrSO",
        "outputId": "8f6f3bb9-39c9-42f4-e8e6-add1fb02905b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0162-8828 (c) 2016 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more\n",
            "information.This article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI\n",
            "10.1109/TPAMI.2016.2577031, IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
            "1\n",
            "Faster R-CNN: Towards Real-Time Object\n",
            "Detection with Region Proposal Networks\n",
            "Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun\n",
            "Abstract—State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations.\n",
            "Advances like SPPnet [1] and Fast R-CNN [2] have reduced the running time of these detection networks, exposing region\n",
            "proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image\n",
            "convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional\n",
            "network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to\n",
            "generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN\n",
            "into a single network by sharing their convolutional features—using the recently popular terminology of neural networks with\n",
            "’attention’ mechanisms, the RPN component tells the uniﬁed network where to look. For the very deep VGG-16 model [3],\n",
            "our detection system has a frame rate of 5fps (including all steps ) on a GPU, while achieving state-of-the-art object detection\n",
            "accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO\n",
            "2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been\n",
            "made publicly available.\n",
            "Index Terms—Object Detection, Region Proposal, Convolutional Neural Network.\n",
            "F\n",
            "1 I NTRODUCTION 1\n",
            "Recent advances in object detection are driven by 2\n",
            "the success of region proposal methods (e.g., [4]) 3\n",
            "and region-based convolutional neural networks (R- 4\n",
            "CNNs) [5]. Although region-based CNNs were com- 5\n",
            "putationally expensive as originally developed in [5], 6\n",
            "their cost has been drastically reduced thanks to shar- 7\n",
            "ing convolutions across proposals [1], [2]. The latest 8\n",
            "incarnation, Fast R-CNN [2], achieves near real-time 9\n",
            "rates using very deep networks [3], when ignoring the 10\n",
            "time spent on region proposals. Now, proposals are the 11\n",
            "test-time computational bottleneck in state-of-the-art 12\n",
            "detection systems. 13\n",
            "Region proposal methods typically rely on inex- 14\n",
            "pensive features and economical inference schemes. 15\n",
            "Selective Search [4], one of the most popular meth- 16\n",
            "ods, greedily merges superpixels based on engineered 17\n",
            "low-level features. Yet when compared to efﬁcient 18\n",
            "detection networks [2], Selective Search is an order of 19\n",
            "magnitude slower, at 2 seconds per image in a CPU 20\n",
            "implementation. EdgeBoxes [6] currently provides the 21\n",
            "best tradeoff between proposal quality and speed, 22\n",
            "at 0.2 seconds per image. Nevertheless, the region 23\n",
            "proposal step still consumes as much running time 24\n",
            "as the detection network. 25\n",
            "\u000fS. Ren is with University of Science and Technology of China, Hefei,\n",
            "China. This work was done when S. Ren was an intern at Microsoft\n",
            "Research. Email: sqren@mail.ustc.edu.cn\n",
            "\u000fK. He and J. Sun are with Visual Computing Group, Microsoft\n",
            "Research. E-mail:fkahe,jiansung@microsoft.com\n",
            "\u000fR. Girshick is with Facebook AI Research. The majority of this work\n",
            "was done when R. Girshick was with Microsoft Research. E-mail:\n",
            "rbg@fb.comOne may note that fast region-based CNNs take 26\n",
            "advantage of GPUs, while the region proposal meth- 27\n",
            "ods used in research are implemented on the CPU, 28\n",
            "making such runtime comparisons inequitable. An ob- 29\n",
            "vious way to accelerate proposal computation is to re- 30\n",
            "implement it for the GPU. This may be an effective en- 31\n",
            "gineering solution, but re-implementation ignores the 32\n",
            "down-stream detection network and therefore misses 33\n",
            "important opportunities for sharing computation. 34\n",
            "In this paper, we show that an algorithmic change— 35\n",
            "computing proposals with a deep convolutional neu- 36\n",
            "ral network—leads to an elegant and effective solution 37\n",
            "where proposal computation is nearly cost-free given 38\n",
            "the detection network’s computation. To this end, we 39\n",
            "introduce novel Region Proposal Networks (RPNs) that 40\n",
            "share convolutional layers with state-of-the-art object 41\n",
            "detection networks [1], [2]. By sharing convolutions at 42\n",
            "test-time, the marginal cost for computing proposals 43\n",
            "is small (e.g., 10ms per image). 44\n",
            "Our observation is that the convolutional feature 45\n",
            "maps used by region-based detectors, like Fast R- 46\n",
            "CNN, can also be used for generating region pro- 47\n",
            "posals. On top of these convolutional features, we 48\n",
            "construct an RPN by adding a few additional con- 49\n",
            "volutional layers that simultaneously regress region 50\n",
            "bounds and objectness scores at each location on a 51\n",
            "regular grid. The RPN is thus a kind of fully convo- 52\n",
            "lutional network (FCN) [7] and can be trained end-to- 53\n",
            "end speciﬁcally for the task for generating detection 54\n",
            "proposals. 55\n",
            "RPNs are designed to efﬁciently predict region pro- 56\n",
            "posals with a wide range of scales and aspect ratios. In 57\n",
            "contrast to prevalent methods [8], [9], [1], [2] that use 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Closing the Files.\n",
        "\n",
        "file1.close()\n",
        "file2.close()\n",
        "file3.close()"
      ],
      "metadata": {
        "id": "Lm69dIV8JvC6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "rhw-XNEoJ1w_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Segments Extraction (In our case: TITLE AND JOURNAL NAME)**"
      ],
      "metadata": {
        "id": "FQ7nm26oCsyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the Data into List Format so that we can access any particular Line Number.\n",
        "\n",
        "linesInListFormatForFile1 = data1.splitlines()\n",
        "\n",
        "linesInListFormatForFile2 = data2.splitlines()\n",
        "\n",
        "linesInListFormatForFile3 = data3.splitlines()"
      ],
      "metadata": {
        "id": "C9T7rq91_kua"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Extracting and Displaying the TITLES of All the 3 PDF Files.**"
      ],
      "metadata": {
        "id": "f4WpAlUMKk7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting TITLE/ JOURNAL NAME in List Format from 1st File.\n",
        "\n",
        "linesInListFormatForFile1[4:7]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7Wm2zt92Al9-",
        "outputId": "a63a15f6-9069-49ee-8041-62d6bbec7696"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SegNet: A Deep Convolutional',\n",
              " 'Encoder-Decoder Architecture for Scene',\n",
              " 'Segmentation']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting TITLE/ JOURNAL NAME in List Format from 2nd File.\n",
        "\n",
        "linesInListFormatForFile2[3:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UbAhuAtzK_EN",
        "outputId": "83d9074c-4d95-4049-c109-a503be2bef79"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Image Segmentation Using Deep Learning:', 'A Survey']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting TITLE/ JOURNAL NAME in List Format from 3rd File.\n",
        "\n",
        "linesInListFormatForFile3[4:6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "T-4vjZhwLGnN",
        "outputId": "92315e6f-920e-4ab8-b884-7dd8dbb5625d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Faster R-CNN: Towards Real-Time Object',\n",
              " 'Detection with Region Proposal Networks']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "eC_XXiMHLWp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Our Title is in Splitted Format in List, so we need to Join them and Make a Single String to work further on it.**"
      ],
      "metadata": {
        "id": "77Sy1H9ZLXu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Joining the Title for 1st File.\n",
        "\n",
        "d1 = linesInListFormatForFile1[4:7]\n",
        "resultant_title_1 = \"\".join(d1)\n",
        "\n",
        "print(resultant_title_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "r03LKUoULLYZ",
        "outputId": "88afb10b-4140-43e6-f7ab-23cac37dbc51"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SegNet: A Deep ConvolutionalEncoder-Decoder Architecture for SceneSegmentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Joining the Title for 2nd File.\n",
        "\n",
        "d2 = linesInListFormatForFile2[3:5]\n",
        "resultant_title_2 = \"\".join(d2)\n",
        "\n",
        "print(resultant_title_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BpquVWE3L4Hm",
        "outputId": "a8a0aa3e-011a-4f95-a45c-fdb3f2aee869"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Segmentation Using Deep Learning:A Survey\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Joining the Title for 3rd File.\n",
        "\n",
        "d3 = linesInListFormatForFile3[4:6]\n",
        "resultant_title_3 = \"\".join(d3)\n",
        "\n",
        "print(resultant_title_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eHa2xtSoL_3p",
        "outputId": "2c6c5fd0-6ba3-469c-f802-88e5e1181245"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Faster R-CNN: Towards Real-Time ObjectDetection with Region Proposal Networks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "edzhnBMNMO8f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing and Feature Engineering**"
      ],
      "metadata": {
        "id": "UD9mYXtODGSC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Operations:**"
      ],
      "metadata": {
        "id": "0tfVsB7qDN8L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **# Text tokenisation and lower casing.**"
      ],
      "metadata": {
        "id": "rKT__7czDS5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In Text based feature extraction, we either Convert the text in Uppercase or Lowercase.\n",
        "# Here we will convert in Lowercase.\n",
        "\n",
        "\n",
        "data1 = resultant_title_1\n",
        "\n",
        "data2 = resultant_title_2\n",
        "\n",
        "data3 = resultant_title_3"
      ],
      "metadata": {
        "id": "aPQd8y9NCIZK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lower() is the builtin function that will lowercase the text.\n",
        "\n",
        "data1 = data1.lower()\n",
        "\n",
        "data2 = data2.lower()\n",
        "\n",
        "data3 = data3.lower()"
      ],
      "metadata": {
        "id": "p-UIucFuNU21"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Outputs after Lowercasing All the 3 Documents:\\n\\n\")\n",
        "\n",
        "print(data1)\n",
        "print()\n",
        "print(data2)\n",
        "print()\n",
        "print(data3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Pj_phx1sNg6d",
        "outputId": "6bbcfb58-2956-4379-b990-2cfd6b0af4bd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs after Lowercasing All the 3 Documents:\n",
            "\n",
            "\n",
            "segnet: a deep convolutionalencoder-decoder architecture for scenesegmentation\n",
            "\n",
            "image segmentation using deep learning:a survey\n",
            "\n",
            "faster r-cnn: towards real-time objectdetection with region proposal networks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "I12bNhgHOEgx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **# Removing Stop Words. (In our case, we can see that from 3 Titles given above, the 1st title has the stopword \"a\" that we need to remove.**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### **# Removing Punctuations. (In our case, we can see that from 3 Titles given above, All of them have semicolon \":\" and dash \"-\" as punctuation marks, so we need to remove both.**"
      ],
      "metadata": {
        "id": "tZfb2paGZYvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing nltk library and Downloading the \"stopwords\" from it which contains all the stopwords present in every language.\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "\n",
        "# Corpus generally means a Document, specifically saying \"Text Document\".\n",
        "from nltk.corpus import stopwords as sw\n",
        "\n",
        "\n",
        "# This will list down all the stop words present in English language.\n",
        "\", \".join(sw.words(\"english\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "eFu2gxK71PAj",
        "outputId": "07e3a64c-fcdb-410e-f48b-202a82102132"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his, himself, she, she's, her, hers, herself, it, it's, its, itself, they, them, their, theirs, themselves, what, which, who, whom, this, that, that'll, these, those, am, is, are, was, were, be, been, being, have, has, had, having, do, does, did, doing, a, an, the, and, but, if, or, because, as, until, while, of, at, by, for, with, about, against, between, into, through, during, before, after, above, below, to, from, up, down, in, out, on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any, both, each, few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too, very, s, t, can, will, just, don, don't, should, should've, now, d, ll, m, o, re, ve, y, ain, aren, aren't, couldn, couldn't, didn, didn't, doesn, doesn't, hadn, hadn't, hasn, hasn't, haven, haven't, isn, isn't, ma, mightn, mightn't, mustn, mustn't, needn, needn't, shan, shan't, shouldn, shouldn't, wasn, wasn't, weren, weren't, won, won't, wouldn, wouldn't\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \"for\" and \"with\", which are the stop words are actually not removed from the text\n",
        "# so to remove it completely, do the below steps means clean the data and preprocess it.\n",
        "\n",
        "\n",
        "# Library to help us with above given tasks.\n",
        "import spacy\n",
        "\n",
        "\n",
        "# Loading english language model and create nlp object from it.\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "def pre_process_data(text):\n",
        "  document = nlp(text)\n",
        "\n",
        "  filtered_words = []\n",
        "\n",
        "  for word in document:\n",
        "    # Just ignore or remove the stopwords to clean the data so that we can put it in the model\n",
        "    if word.is_stop or word.is_punct:\n",
        "      continue\n",
        "\n",
        "    # Store the other remaining words into a list\n",
        "    # lemma_ in lemmetization gives us the base word\n",
        "    # Example: For \"learning\" it will give \"learn\" as base word\n",
        "    filtered_words.append(word.lemma_)\n",
        "\n",
        "\n",
        "  # We want the result in string/ text format so convert the list into string\n",
        "  return \" \".join(filtered_words)"
      ],
      "metadata": {
        "id": "ydO_qDHWe_wH"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = pre_process_data(data1)\n",
        "data2 = pre_process_data(data2)\n",
        "data3 = pre_process_data(data3)"
      ],
      "metadata": {
        "id": "agXi2acdfr7T"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data 1 after pre processing:\\n\")\n",
        "print(data1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vfKCitUsf0Ed",
        "outputId": "2eab6d62-8a2e-4ca5-be24-1cd3d213c18f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data 1 after pre processing:\n",
            "\n",
            "segnet deep convolutionalencoder decoder architecture scenesegmentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data 2 after pre processing:\\n\")\n",
        "print(data2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IYBhqzOff1ld",
        "outputId": "c4a6200c-7082-4e72-ab30-6af1cda05856"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data 2 after pre processing:\n",
            "\n",
            "image segmentation deep learning survey\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data 3 after pre processing:\\n\")\n",
        "print(data3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xPd9X4fcf4wl",
        "outputId": "0fb5c47c-9310-46a5-a2e7-196c46922e40"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data 3 after pre processing:\n",
            "\n",
            "fast r cnn real time objectdetection region proposal network\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "3ZbPagH1PhIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **# Inserting spaces between the data of all 3 documents given above.**"
      ],
      "metadata": {
        "id": "aCW04RlbQrau"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **For 1st Document.**"
      ],
      "metadata": {
        "id": "pol4RUJcTLsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the Function for the same.\n",
        "def insert_space(string, index):\n",
        "  return string[:index] + \" \" + string[index:]\n",
        "\n",
        "\n",
        "# Calling the Function for 1st Document.\n",
        "\n",
        "data1 = insert_space(data1, 25)\n",
        "print(data1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nFZWWpbS_Gvv",
        "outputId": "63386c0d-e16a-4d2c-e2e4-d11dfbc98e9d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "segnet deep convolutional encoder decoder architecture scenesegmentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = insert_space(data1, 60)\n",
        "print(data1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_-l4P004Q88d",
        "outputId": "1ae1de53-1733-4aef-ebe4-be62b6448693"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "segnet deep convolutional encoder decoder architecture scene segmentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **For 3rd Document.**"
      ],
      "metadata": {
        "id": "btNjRk2TUdJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calling the Function for 3rd Document.\n",
        "\n",
        "data3 = insert_space(data3, 27)\n",
        "print(data3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TG3gWjUKUQso",
        "outputId": "d4336fbc-ee6d-419d-f310-fcd7d8d64dfb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fast r cnn real time object detection region proposal network\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **After adding the spaces and removing the punctuations, printing the data.**"
      ],
      "metadata": {
        "id": "TRURXlbPVgTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Title from Document 1:\\n\")\n",
        "print(data1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KNpVTPGqUQUd",
        "outputId": "f3591c82-0fbb-49fa-9061-4f6afb7fecb5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title from Document 1:\n",
            "\n",
            "segnet deep convolutional encoder decoder architecture scene segmentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Title from Document 2:\\n\")\n",
        "print(data2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Gg3OcOTXV0KG",
        "outputId": "c15cfcf4-8028-45ff-9a2d-da623ec9a54b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title from Document 2:\n",
            "\n",
            "image segmentation deep learning survey\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Title from Document 3:\\n\")\n",
        "print(data3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IBvCUESWV2kK",
        "outputId": "e47a5f76-6add-4d89-f463-f7b102dc9f00"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title from Document 3:\n",
            "\n",
            "fast r cnn real time object detection region proposal network\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Am2av5jrWX_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **# Feature Engineering on Text Data - Feature Extraction**"
      ],
      "metadata": {
        "id": "qJM-g_rXWY_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data1)\n",
        "print()\n",
        "print(data2)\n",
        "print()\n",
        "print(data3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RQugdMYiIs_R",
        "outputId": "d5a4acdf-25fc-447d-9d5d-475606f5545c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "segnet deep convolutional encoder decoder architecture scene segmentation\n",
            "\n",
            "image segmentation deep learning survey\n",
            "\n",
            "fast r cnn real time object detection region proposal network\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Converting the String/ Text Data into Vector Format so that we can feed it into the Model.**"
      ],
      "metadata": {
        "id": "FFU3DeUvW4YO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data1_list_format = data1.split()\n",
        "\n",
        "print(data1_list_format)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sw3ch_k_aGUQ",
        "outputId": "58e25adc-1b25-41c5-dd5b-8f7e024d6c49"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['segnet', 'deep', 'convolutional', 'encoder', 'decoder', 'architecture', 'scene', 'segmentation']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data2_list_format = data2.split()\n",
        "\n",
        "print(data2_list_format)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "P6rcdA43aznZ",
        "outputId": "342e0bb7-a0bc-4f31-d336-adcf3feb84de"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['image', 'segmentation', 'deep', 'learning', 'survey']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data3_list_format = data3.split()\n",
        "\n",
        "print(data3_list_format)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZUNk2MUEXQ7N",
        "outputId": "00d93d06-e262-418b-e49e-ced41c451647"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fast', 'r', 'cnn', 'real', 'time', 'object', 'detection', 'region', 'proposal', 'network']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "N0eJ9LJNXXR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the CountVectorizer() from sklearn library.\n",
        "# CountVectorizer() converts a collection of text documents to a matrix of token counts.\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "# Create the transform\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "\n",
        "# Take any of the data to feed in this model, In our case we are taking \"data2_list_format\"\n",
        "# Tokenize and Build Vocabulary from the words that are present in \"data2_list_format\"\n",
        "vectorizer.fit(data2_list_format)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uHxrtWUBa10p",
        "outputId": "14b22c53-80ef-4e2f-a40f-92d198b56d94"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer()"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize the Data\n",
        "\n",
        "print(vectorizer.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TMdyZjKgbF7U",
        "outputId": "7032f1ae-4bcc-4901-cf2f-dc9627358ba9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'image': 1, 'segmentation': 3, 'deep': 0, 'learning': 2, 'survey': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Word Vector - Made this in Excel.**\n",
        "## **All words represents a particular value in above cell.**\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "F8wcwZe0cJ82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding the Document\n",
        "\n",
        "# Now fit this sample text in the vector\n",
        "sample_text = [\"Hello I am Vedant, this pdf is on image image segmentation\"]\n",
        "\n",
        "new_vector = vectorizer.transform(sample_text)\n",
        "\n",
        "# Summarize the encoded vector\n",
        "print(new_vector.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bSTpHrjCbSgt",
        "outputId": "be282ee0-2e0f-4437-e7da-ab28a04d9639"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 2 0 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Observations:**\n",
        "1. ### So from the above 2 cells, we can see that the words \"**image**\" and \"**segmentation**\" are present in our **Extracted title from document 2** and the **Sample Text** that we tested, hence it has values as 1 and else all are 0.\n",
        "2. ### If there are **common words** between documents then the value will become **1** else if **not common** then value will become **0**.\n",
        "3. ### If same word is present **multiple** times then it shows the **total count** as well. In above cell we can see that \"image\" word is appeared 2 times hence in the array, it shows value as \"2\" on 1st index which points to \"image\" on the **excel** sheet diagram.\n",
        "\n",
        "\n",
        "---\n",
        "### Hence, the above approach is **Not as useful** because if one document talks about \"Image Segmentation\" and other talks about \"RNN's\" then it is **not able to differentiate** between both, hence it is not very helpful. so we make use of **TF - IDF method**, which is given below.\n"
      ],
      "metadata": {
        "id": "7-v3uNsGaH49"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Jifwztd-b4OD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TF - IDF (Term Frequency - Inverse Document Frequency)**"
      ],
      "metadata": {
        "id": "PZwisGJzpU3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TF** means Term frequency is nothing but counting the frequency in each document."
      ],
      "metadata": {
        "id": "UvYH3LJeb5cP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **IDF** is there to suppress the effect of words that are appearing in all the documents, because if the words that are appearing frequently in all th documents are taken then the value becomes very high and we are not able to give importance to other words that are really helpful for us."
      ],
      "metadata": {
        "id": "9n2BpdpNcIRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the TfidfVectorizer() from sklearn library.\n",
        "# TfidfVectorizer() converts a collection of raw documents to a matrix of TF-IDF features.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# List of random 3 text documents separated by commas\n",
        "text_documents = [ data1,\n",
        "                   data2,\n",
        "                   data3 ]"
      ],
      "metadata": {
        "id": "3ZA9lKgLpn5H"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Transform\n",
        "vectorizer = TfidfVectorizer()"
      ],
      "metadata": {
        "id": "CRc-cdnZqBw0"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Model by fitting the text_documents.\n",
        "vectorizer.fit(text_documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UwW9a6NnqGa0",
        "outputId": "41802d42-24c5-419a-e254-e7d9806d22c5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer()"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize - Printing the words from documents.\n",
        "\n",
        "print(vectorizer.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1Tti5WSfqJHL",
        "outputId": "09b4bc59-4c2f-4a1c-bf17-08fde2f19b4d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'segnet': 17, 'deep': 4, 'convolutional': 2, 'encoder': 6, 'decoder': 3, 'architecture': 0, 'scene': 15, 'segmentation': 16, 'image': 8, 'learning': 9, 'survey': 18, 'fast': 7, 'cnn': 1, 'real': 13, 'time': 19, 'object': 11, 'detection': 5, 'region': 14, 'proposal': 12, 'network': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Word Vector Value Representation - Made this in Excel.**\n",
        "## **All words represents a particular value in above cell.**\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "FoJoWBqFtpfr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Observations:**\n",
        "1. ### The **words** that are appearing **most frequently** has the lowest value as they can't give us more details about a particular document.\n",
        "2. ### The **words** that are **Unique** are considered as that helps us to find the **Importance of a word** in any particular document."
      ],
      "metadata": {
        "id": "YN6hvHwjlaSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The IDF Values\n",
        "print(vectorizer.idf_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fD7jMAiNrmj8",
        "outputId": "27f26249-413c-4e63-ff10-66651f9d88ce"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.69314718 1.69314718 1.69314718 1.69314718 1.28768207 1.69314718\n",
            " 1.69314718 1.69314718 1.69314718 1.69314718 1.69314718 1.69314718\n",
            " 1.69314718 1.69314718 1.69314718 1.69314718 1.28768207 1.69314718\n",
            " 1.69314718 1.69314718]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Observations:**\n"
      ],
      "metadata": {
        "id": "3VW99zormnsS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Trying the same above steps but using Sample Random Raw Data.**"
      ],
      "metadata": {
        "id": "LMWuh6mUmsK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text_documents = [ \"Hello I am Vedant from AI/ML Field\",\n",
        "                   \"AI is getting popular day by day\",\n",
        "                   \"User's Data is the most important thing in today's world\" ]"
      ],
      "metadata": {
        "id": "uHLWLnvJu6Mg"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()"
      ],
      "metadata": {
        "id": "8oFpimOmm2AT"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.fit(sample_text_documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sB0tDpgcm-wx",
        "outputId": "9417a47f-ab41-4478-a194-3622a6762db3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer()"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorizer.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0dm2TMPIvHf7",
        "outputId": "56fd2606-5561-4345-8bba-652f0a296d2e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'hello': 8, 'am': 1, 'vedant': 19, 'from': 6, 'ai': 0, 'ml': 12, 'field': 5, 'is': 11, 'getting': 7, 'popular': 14, 'day': 4, 'by': 2, 'user': 18, 'data': 3, 'the': 15, 'most': 13, 'important': 9, 'thing': 16, 'in': 10, 'today': 17, 'world': 20}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorizer.idf_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "n70tzFaHvOTc",
        "outputId": "932bd5e6-9f19-4007-a858-62e3bd397041"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.28768207 1.69314718 1.69314718 1.69314718 1.69314718 1.69314718\n",
            " 1.69314718 1.69314718 1.69314718 1.69314718 1.69314718 1.28768207\n",
            " 1.69314718 1.69314718 1.69314718 1.69314718 1.69314718 1.69314718\n",
            " 1.69314718 1.69314718 1.69314718]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Observations:**\n",
        "1. ### From the above cell, we can see that **At 2nd Index, the IDF value is 1. which points to \"data\"** if we refer the above given excel sheet data, which is comparatively **less** than other values.\n",
        "2. ### Hence, **Data word** is repeating right, so we have **suppressed it** and **lowered** its **value** so that we get **to know the importance of other unique words**."
      ],
      "metadata": {
        "id": "cF-nA7J6nRr2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "PMSOWQjAoWWl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Passing one document into our Model and obtaining the results.**"
      ],
      "metadata": {
        "id": "7l0KA54GoXR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If we take only one document\n",
        "single_document = sample_text_documents[1]\n",
        "\n",
        "\n",
        "# Fitting the above built model (vectorizer)\n",
        "vector = vectorizer.transform([single_document])"
      ],
      "metadata": {
        "id": "DA7EreQevUZc"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarizing the Encoded Vector\n",
        "print(vector.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "XGPY5l5avuv0",
        "outputId": "bd102e54-9d0b-4c0c-e0cc-c565a101fcc9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.26628951 0.         0.35013871 0.         0.70027741 0.\n",
            "  0.         0.35013871 0.         0.         0.         0.26628951\n",
            "  0.         0.         0.35013871 0.         0.         0.\n",
            "  0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "bDbcVe8Hoirv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Final Observations:**\n",
        "\n",
        "1. ### By using Vector Values, we can understand the Importance of a word present in the document.\n",
        "2. ### TF - IDF method is mostly used when we want to deal with Text Data as it has lots of plus points when compared with the basic CountVectorizer().\n"
      ],
      "metadata": {
        "id": "9dKiuETtokWK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Tn7Mqc4Ljpng"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O8WKGRkykuNa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}